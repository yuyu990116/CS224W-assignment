{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPpgJcCkaIL4pVoCXcVgxl3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yuyu990116/CS224W-assignment/blob/main/P3_peft_advanced.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nlGlTH4bME-M",
        "outputId": "922ca7a4-3ca9-4149-97a6-daa79d955649"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import os\n",
        "os.chdir(\"/content/drive/MyDrive/nlp\")\n",
        "os.environ['CUDA_VISIBLE_DEVICES'] ='0'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install peft==0.5.0\n",
        "!pip install accelerate==0.22.0\n",
        "!pip install transformers==4.33.1\n",
        "import torch\n",
        "from torch import nn\n",
        "from peft import LoraConfig, get_peft_model, PeftModel"
      ],
      "metadata": {
        "id": "9XZ4iPvFN0_J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#lora适配自定义模型"
      ],
      "metadata": {
        "id": "5uCCnUP5N1LI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n1 = nn.Sequential(\n",
        "    nn.Linear(10,10),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(10,2)\n",
        ")\n",
        "n1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KQQs3QK8TH0Z",
        "outputId": "5990b067-11e8-4edb-802e-117f5c0cd8dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Sequential(\n",
              "  (0): Linear(in_features=10, out_features=10, bias=True)\n",
              "  (1): ReLU()\n",
              "  (2): Linear(in_features=10, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for name,param in n1.named_parameters():\n",
        "  print(name,param)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z7MnkAf0TSeR",
        "outputId": "2c92d58e-05e8-43c6-b8c0-aa0a57781370"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.weight Parameter containing:\n",
            "tensor([[ 2.5363e-01, -8.5284e-02, -2.4243e-01, -1.0562e-01, -3.0322e-01,\n",
            "         -3.1527e-01, -1.8856e-02,  1.4177e-01, -2.4148e-01,  2.5017e-01],\n",
            "        [-5.8837e-02,  1.4258e-02,  1.0422e-01,  1.1408e-01,  1.7103e-04,\n",
            "         -2.4463e-01, -2.0892e-01,  7.3016e-02,  4.7191e-02, -8.7792e-02],\n",
            "        [-8.1819e-02,  2.4983e-01,  1.4444e-02,  1.8578e-01, -2.3290e-01,\n",
            "         -8.3650e-02,  9.1456e-02,  2.9422e-02, -4.2514e-02,  1.6925e-01],\n",
            "        [-2.4790e-01,  3.9774e-03, -6.3456e-02,  3.0024e-01, -2.1813e-01,\n",
            "          1.5836e-01,  4.8530e-02,  1.1130e-01, -1.3256e-02,  8.6003e-02],\n",
            "        [ 1.4101e-01,  6.7990e-02,  3.0572e-01,  1.6322e-01,  3.0823e-01,\n",
            "          8.4492e-02,  7.3510e-02,  2.9989e-02, -1.7748e-01, -1.0538e-01],\n",
            "        [ 2.8151e-01, -1.0977e-01, -2.4836e-01, -2.4062e-01, -1.2866e-01,\n",
            "          6.4993e-02,  5.4429e-02, -7.4712e-02, -2.1652e-01,  2.6645e-01],\n",
            "        [-1.5677e-01,  1.9531e-01,  7.3288e-02,  2.0439e-01, -8.5654e-02,\n",
            "          2.9944e-01,  8.8376e-02, -2.5849e-01, -8.7763e-02,  3.0086e-01],\n",
            "        [-2.1866e-01,  1.7541e-01, -2.6809e-01,  2.3650e-01, -1.0906e-01,\n",
            "          8.1033e-02,  1.5505e-01, -5.0901e-02,  1.6897e-01, -2.5736e-02],\n",
            "        [ 9.7324e-02,  1.4922e-02,  6.1984e-02, -1.3341e-01, -3.0212e-01,\n",
            "          4.9983e-03,  1.9453e-01, -9.8218e-02,  7.9236e-02,  2.4037e-01],\n",
            "        [-9.3443e-02,  1.9794e-02,  2.7966e-01,  1.9011e-01, -1.5271e-01,\n",
            "         -1.6616e-01, -6.7802e-02, -6.6365e-03,  5.1023e-02, -1.1289e-01]],\n",
            "       requires_grad=True)\n",
            "0.bias Parameter containing:\n",
            "tensor([ 0.1634, -0.2011, -0.2072, -0.2167, -0.2695, -0.1730, -0.1556, -0.2191,\n",
            "        -0.1528,  0.3076], requires_grad=True)\n",
            "2.weight Parameter containing:\n",
            "tensor([[ 0.1147,  0.1322,  0.2905,  0.0222, -0.1697,  0.0434,  0.0900,  0.0999,\n",
            "          0.1655, -0.0024],\n",
            "        [-0.3057,  0.2139, -0.2444,  0.2023, -0.1751,  0.0753,  0.1386, -0.0435,\n",
            "          0.2763,  0.0689]], requires_grad=True)\n",
            "2.bias Parameter containing:\n",
            "tensor([0.1915, 0.1245], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "config = LoraConfig(target_modules=[\"0\"]) #必须指定是哪一层\n",
        "model1 = get_peft_model(n1,config)\n",
        "model1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Amv7vvE3TXjn",
        "outputId": "5cd89e4b-3bbf-4615-b85b-3636a0d9be15"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PeftModel(\n",
              "  (base_model): LoraModel(\n",
              "    (model): Sequential(\n",
              "      (0): Linear(\n",
              "        in_features=10, out_features=10, bias=True\n",
              "        (lora_dropout): ModuleDict(\n",
              "          (default): Identity()\n",
              "        )\n",
              "        (lora_A): ModuleDict(\n",
              "          (default): Linear(in_features=10, out_features=8, bias=False)\n",
              "        )\n",
              "        (lora_B): ModuleDict(\n",
              "          (default): Linear(in_features=8, out_features=10, bias=False)\n",
              "        )\n",
              "        (lora_embedding_A): ParameterDict()\n",
              "        (lora_embedding_B): ParameterDict()\n",
              "      )\n",
              "      (1): ReLU()\n",
              "      (2): Linear(in_features=10, out_features=2, bias=True)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for name,param in model1.named_parameters():\n",
        "  print(name,param)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ahi--OUCUI2g",
        "outputId": "a48e91c8-08d7-41c5-81c6-947bb3973b62"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "base_model.model.0.weight Parameter containing:\n",
            "tensor([[ 0.1711, -0.1354,  0.1002, -0.2820, -0.1607, -0.2068, -0.2129,  0.0887,\n",
            "          0.0664,  0.1450],\n",
            "        [-0.1965, -0.2049, -0.2242,  0.0610, -0.2919,  0.1789,  0.2719,  0.1356,\n",
            "         -0.1253,  0.1001],\n",
            "        [ 0.0414,  0.0382, -0.2861, -0.1712,  0.0269,  0.0650, -0.1832,  0.1839,\n",
            "          0.0099, -0.0717],\n",
            "        [ 0.2443,  0.0159,  0.1061,  0.2934,  0.0914,  0.1048, -0.2877, -0.0402,\n",
            "          0.0090, -0.1782],\n",
            "        [ 0.0295,  0.0974, -0.1635, -0.2743, -0.0330, -0.1744, -0.2096,  0.0075,\n",
            "         -0.1573, -0.2911],\n",
            "        [ 0.1987,  0.0814,  0.0769,  0.0711, -0.0115,  0.0509,  0.2471, -0.0517,\n",
            "         -0.2011,  0.0488],\n",
            "        [-0.2833, -0.1283, -0.0465, -0.1109,  0.0841,  0.0360, -0.1508, -0.2019,\n",
            "          0.1578,  0.2165],\n",
            "        [ 0.1703,  0.1016,  0.1869,  0.1596,  0.1274, -0.0516,  0.0561, -0.1447,\n",
            "          0.2953,  0.0043],\n",
            "        [ 0.1886, -0.2352,  0.2507, -0.2805,  0.2728,  0.1055, -0.2156, -0.2070,\n",
            "          0.1290,  0.1504],\n",
            "        [ 0.1813,  0.2165, -0.1253,  0.2126, -0.1434, -0.1854,  0.0608, -0.1891,\n",
            "         -0.0853,  0.2459]])\n",
            "base_model.model.0.bias Parameter containing:\n",
            "tensor([-0.0017,  0.2162,  0.2196, -0.0142, -0.0951,  0.0712,  0.2551,  0.2706,\n",
            "        -0.2566,  0.0591])\n",
            "base_model.model.0.lora_A.default.weight Parameter containing:\n",
            "tensor([[ 0.0940, -0.0576, -0.1758, -0.1615, -0.0573, -0.1201,  0.2203,  0.1555,\n",
            "         -0.1950,  0.0443],\n",
            "        [-0.1831,  0.1691,  0.2617, -0.0994,  0.2013,  0.0476,  0.2371,  0.0869,\n",
            "         -0.1026,  0.1551],\n",
            "        [-0.0380,  0.0969,  0.2342,  0.1663, -0.2048, -0.1594,  0.2596, -0.0505,\n",
            "          0.0270,  0.2732],\n",
            "        [ 0.3081, -0.1464,  0.1057,  0.2163,  0.1491, -0.0159, -0.0205,  0.2768,\n",
            "         -0.3043, -0.3109],\n",
            "        [-0.0672, -0.0935,  0.0716, -0.1773,  0.0778,  0.3005, -0.1546,  0.0105,\n",
            "          0.1398,  0.2679],\n",
            "        [ 0.1723, -0.0913,  0.1466, -0.1500, -0.0280,  0.0918, -0.1980,  0.1857,\n",
            "          0.1896,  0.0359],\n",
            "        [ 0.0323, -0.2515,  0.0439, -0.2141,  0.2427,  0.2555, -0.2491, -0.1285,\n",
            "          0.3102, -0.1384],\n",
            "        [-0.2488,  0.1993,  0.0133, -0.0235, -0.0231, -0.2693,  0.2758, -0.0341,\n",
            "          0.0111,  0.1827]], requires_grad=True)\n",
            "base_model.model.0.lora_B.default.weight Parameter containing:\n",
            "tensor([[0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0.],\n",
            "        [0., 0., 0., 0., 0., 0., 0., 0.]], requires_grad=True)\n",
            "base_model.model.2.weight Parameter containing:\n",
            "tensor([[-0.2340,  0.2744, -0.0873,  0.0750,  0.2073, -0.0363, -0.1572,  0.1148,\n",
            "          0.1765,  0.0915],\n",
            "        [-0.0418,  0.2322, -0.0336,  0.0372, -0.1043,  0.1019,  0.1104, -0.2063,\n",
            "          0.0216,  0.2044]])\n",
            "base_model.model.2.bias Parameter containing:\n",
            "tensor([-0.1227, -0.2600])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#一个主模型，多个适配器"
      ],
      "metadata": {
        "id": "SVsoYm1PN5_3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n1 = nn.Sequential(\n",
        "    nn.Linear(10,10),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(10,2)\n",
        ")\n",
        "\n",
        "config1 = LoraConfig(target_modules=[\"0\"])\n",
        "model2 = get_peft_model(n1, config1)\n",
        "model2.save_pretrained(\"./loraA\")\n",
        "\n",
        "n1 = nn.Sequential(\n",
        "    nn.Linear(10,10),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(10,2)\n",
        ")\n",
        "config2 = LoraConfig(target_modules=[\"2\"])\n",
        "model3 = get_peft_model(n1, config2)\n",
        "model3.save_pretrained(\"./loraB\")"
      ],
      "metadata": {
        "id": "rhNrhLYxUmsH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n1 = nn.Sequential(\n",
        "    nn.Linear(10,10),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(10,2)\n",
        ")\n",
        "model4 = PeftModel.from_pretrained(n1, model_id=\"./loraA/\", adapter_name=\"loraA\")\n",
        "model4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i7u-YOCRXU1z",
        "outputId": "c86d29c4-cff8-4458-b76c-ed60a062c842"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PeftModel(\n",
              "  (base_model): LoraModel(\n",
              "    (model): Sequential(\n",
              "      (0): Linear(\n",
              "        in_features=10, out_features=10, bias=True\n",
              "        (lora_dropout): ModuleDict(\n",
              "          (loraA): Identity()\n",
              "        )\n",
              "        (lora_A): ModuleDict(\n",
              "          (loraA): Linear(in_features=10, out_features=8, bias=False)\n",
              "        )\n",
              "        (lora_B): ModuleDict(\n",
              "          (loraA): Linear(in_features=8, out_features=10, bias=False)\n",
              "        )\n",
              "        (lora_embedding_A): ParameterDict()\n",
              "        (lora_embedding_B): ParameterDict()\n",
              "      )\n",
              "      (1): ReLU()\n",
              "      (2): Linear(in_features=10, out_features=2, bias=True)\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model4.load_adapter(\"./loraB/\", adapter_name=\"loraB\")\n",
        "model4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gX3feejlOAWg",
        "outputId": "6642ca32-588a-4cd3-fc9a-2229f1126b21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PeftModel(\n",
              "  (base_model): LoraModel(\n",
              "    (model): Sequential(\n",
              "      (0): Linear(\n",
              "        in_features=10, out_features=10, bias=True\n",
              "        (lora_dropout): ModuleDict(\n",
              "          (loraA): Identity()\n",
              "        )\n",
              "        (lora_A): ModuleDict(\n",
              "          (loraA): Linear(in_features=10, out_features=8, bias=False)\n",
              "        )\n",
              "        (lora_B): ModuleDict(\n",
              "          (loraA): Linear(in_features=8, out_features=10, bias=False)\n",
              "        )\n",
              "        (lora_embedding_A): ParameterDict()\n",
              "        (lora_embedding_B): ParameterDict()\n",
              "      )\n",
              "      (1): ReLU()\n",
              "      (2): Linear(\n",
              "        in_features=10, out_features=2, bias=True\n",
              "        (lora_dropout): ModuleDict(\n",
              "          (loraB): Identity()\n",
              "        )\n",
              "        (lora_A): ModuleDict(\n",
              "          (loraB): Linear(in_features=10, out_features=8, bias=False)\n",
              "        )\n",
              "        (lora_B): ModuleDict(\n",
              "          (loraB): Linear(in_features=8, out_features=2, bias=False)\n",
              "        )\n",
              "        (lora_embedding_A): ParameterDict()\n",
              "        (lora_embedding_B): ParameterDict()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model4.active_adapter #查看现在是哪个LOra在起作用"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "tEsLhyjXU3CO",
        "outputId": "73b5b036-2dc7-481c-b904-1aee92bf6a50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'loraB'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model4.set_adapter(\"loraB\") #切换lora"
      ],
      "metadata": {
        "id": "q2ZlvpdDU-Bt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#禁用适配器\n",
        "with model2.disable_adapter():\n",
        "    print(model2(torch.arange(0, 10).view(1, 10).float()))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3kqsS7ZLV_GV",
        "outputId": "195cda11-05aa-4ec0-8f28-c5030c7a308f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[0.7081, 0.8522]])\n"
          ]
        }
      ]
    }
  ]
}